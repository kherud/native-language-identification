Agglomerative Bregman Clustering

Matus Telgarsky
mtelgars@cs.ucsd.edu
Sanjoy Dasgupta
dasgupta@cs.ucsd.edu
Department of Computer Science and Engineering, UCSD, 9500 Gilman Drive, La Jolla, CA 92093-0404

Abstract
This manuscript develops the theory of agglomerative clustering with Bregman divergences. Geometric smoothing techniques are
developed to deal with degenerate clusters.
To allow for cluster models based on exponential families with overcomplete representations, Bregman divergences are developed
for nondifferentiable convex functions.

1. Introduction
Starting with points {xi }m
i=1 and a pairwise merge cost
∆(·, ·), classical agglomerative clustering produces a
single hierarchical tree as follows (Duda et al., 2001).
1. Start with m clusters: Ci := {xi } for each i.
2. While at least two clusters remain:
(a) Choose {Ci , Cj } with minimal ∆(Ci , Cj ).
(b) Remove {Ci , Cj }, add in Ci ∪ Cj .
In order to build a hierarchy with low k-means cost,
one can use the merge cost due to Ward (1963),
∆w (Ci , Cj ) :=

|Ci ||Cj |
kτ (Ci ) − τ (Cj )k22 ,
|Ci | + |Cj |

1.1. Bregman clustering
There is already a rich theory of clustering with Bregman divergences, and in particular the relationship
of these divergences with exponential family distributions (Banerjee et al., 2005). The standard development has two shortcomings, the first of which is amplified in the agglomerative setting.
Degenerate divergences. Many divergences lead to
merge costs which are undefined on certain inputs.
This scenario is exacerbated with small clusters;
for instance, with Gaussian clusters, the corresponding divergence rule is the KL divergence,
which demands full rank cluster covariances. This
is impossible with ≤ d points, but the agglomerative procedure above starts with singletons.
Minimal representations. The standard theory of
exponential families and its connections to Bregman divergences depend on minimal representations: there is just one way to write down any
particular distribution. On the other hand, the
natural encoding for many problems — e.g., Ising
models, and many other examples listed in the
textbook of Wainwright & Jordan (2008, Section
4) — is overcomplete, necessitating potentially tedious conversions to invoke the theory.

where τ (C) denotes the mean of cluster C.

1.2. Contribution

The k-means cost, and thus the Ward merge rule, inherently prefer spherical clusters of common radius.
To accommodate other cluster shapes and input domains, the squared Euclidean norm may be replaced
with a relaxation sharing many of the same properties,
a Bregman divergence.

The approach of this manuscript is to carefully build a
theory of Bregman divergences constructed from convex, yet nondifferentiable functions. Section 2 will
present the basic definition, and verify this generalization satisfies the usual Bregman divergence properties.

This manuscript develops the theory of agglomerative
clustering with Bregman divergences.
Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012.
Copyright 2012 by the author(s)/owner(s).

Section 3 will revisit the standard Bregman hard clustering model (Banerjee et al., 2005), and show how it
naturally leads to a merge cost ∆. Section 4 then constructs exponential families, demonstrating that nondifferentiable Bregman divergences, while permitting
representations which are not minimal, still satisfy
all the usual properties. To overcome the aforemen-

Agglomerative Bregman Clustering

tioned small-sample cases where divergences may not
be well-defined, Section 5 presents smoothing procedures which immediately follow from the preceding
technical development.
To close, Section 6 presents the final algorithm, and
Section 7 provides experimental validation both by
measuring cluster fit, and the suitability of cluster features in supervised learning tasks.
The various appendices contain all proofs, as well as
some additional technical material and examples.
1.3. Related work
A number of works present agglomerative schemes
for clustering with exponential families, from the perspective of KL divergences between distributions, or
the analogous goal of maximizing model likelihood,
or lastly in connection to the information bottleneck
method (Iwayama & Tokunaga, 1995; Fraley, 1998;
Heller & Ghahramani, 2005; Garcia et al., 2010; Blundell et al., 2010; Slonim & Tishby, 1999). Furthermore, Merugu (2006) studied the same algorithm as
the present work, phrased in terms of Bregman divergences. These preceding methods either do not explicitly mention divergence degeneracies, or circumvent
them with Bayesian techniques, a connection discussed
in Section 5.
Bregman divergences for nondifferentiable functions
have been studied in a number of places. Remark 2.4
shows the relationship between the presented version,
and one due to Gordon (1999). Furthermore, Kiwiel
(1995) presents divergences almost identical to those
here, but the manuscripts and focuses differ thereafter.
The development here of exponential families and related Bregman properties generalizes results found in
a variety of sources (Brown, 1986; Azoury & Warmuth, 2001; Banerjee et al., 2005; Wainwright & Jordan, 2008); further bibliographic remarks will appear
throughout, and in Appendix G. Finally, parallel to
the completion of this manuscript, another group has
developed exponential families under similarly relaxed
conditions, but from the perspective of maximum entropy and convex duality (Csiszár & Matúš, 2012).
1.4. Notation
The following concepts from convex analysis are used
throughout the text; the interested reader is directed
to the seminal text of Rockafellar (1970). A set is
convex when the line segment between any two of its
elements is again within the set. The epigraph of a
function f : Rn → R̄, where R̄ = R ∪ {±∞}, is
the set of points bounded below by f ; i.e., the set

{(x, r) : x ∈ Rn , r ≥ f (x)} ⊆ Rn × R̄. A function is
convex when its epigraph is convex, and closed when
its epigraph is closed. The domain dom(f ) of a function f : Rn → R̄ is the subset of inputs not mapping
to +∞: dom(f ) = {x ∈ Rn : f (x) < ∞}. A function
is proper if dom(f ) is nonempty, and f never takes
on the value −∞. The Bregman divergences in this
manuscript will be generated from closed proper convex functions.
The conjugate of a function f is the function f ∗ (φ) :=
supx hφ, xi − f (x); when f is closed proper convex,
so is f ∗ , and moreover f ∗∗ = f . A subgradient g to
a function f at y ∈ dom(f ) provides an affine lower
bound: for any x ∈ Rn , f (x) ≥ f (y) + hg, x − yi.
The set of all subgradients at a point y is denoted
by ∂f (y) (which is easily empty). The directional
derivative f 0 (y; d) of a function f at y in direction d is
limt↓0 (f (y + td) − f (y))/t.
The affine hull of a set S ⊆ Rn is the smallest affine set
containing it. If S is translated and rotated so that its
affine hull is some Rd ⊆ Rn , then its interior within Rd
is its relative interior within Rn . Said another way, the
relative interior ri(S) is the interior of S with respect
to the Rn topology relativized to the affine hull of S.
Although functions in this manuscript will generally
be closed, their domains are often (relatively) open.
Convex functions will be defined over Rn , but it will
be useful to treat data as lying in an abstract space X ,
and a statistic map τ : X → Rn will embed examples
in the desired Euclidean space. This map, which will
also be overloaded to handle finite subsets of X , will
eventually incorporate the smoothing procedure.
The cluster cost will be denoted by φ, or φf,τ to make
the underlying convex function and statistic map clear;
similarly, the merge cost is denoted by ∆ and ∆f,τ .

2. Bregman divergences
Given a convex function f : Rn → R̄, the Bregman
divergence Bf (·, y) is the gap between f and its linearization at y. Typically, f is differentiable, and so
Bf (x, y) = f (x) − f (y) − h∇f (y), x − yi.
Definition 2.1. Given a convex function f : Rn → R̄,
the corresponding Bregman divergence between x, y ∈
dom(f ) is
Bf (x, y) := f (x) − f (y) + f 0 (y; y − x).

♦

Unlike gradients, directional derivatives are welldefined whenever a convex function is finite, although
they can be infinite on the relative boundary of dom(f )
(Rockafellar, 1970, Theorems 23.1, 23.3, 23.4).

Agglomerative Bregman Clustering

x1

x2

Remark 2.4. Given x ∈ dom(f ) and a dual element
g ∈ Rn , another nondifferentiable generalization of
Bregman divergence, due to Gordon (1999), is
Df (x, g) := f (x) + f ∗ (g) − hg, xi .

Bf (x1 , y)

y

Bf (x2 , y)

Figure 1. Bregman divergences with respect to a reference
point y at which f is nondifferentiable. The thick (red
or blue) dashed lines denote the divergence values themselves; they travel down from f to the negated sublinear
function x 7→ f (y) − f 0 (y; y − x), here a pair of dotted
rays. Noting Proposition 2.3 and fixing some xi , the subgradient at y farthest from xi is one of these dotted rays
together with its dashed, gray extension. The gray extensions, taken together, represent the sublinear function
x 7→ f (y) + f 0 (y; x − y).

Noting that f 0 (y; y − x) ≥ −f 0 (y; x − y) (Rockafellar,
1970, Theorem 23.1), it may seem closer to the original
expression to instead use f (x) − f (y) − f 0 (y; x − y)
(which is thus bounded above by Bf (x, y)); however,
it will later be shown that Bf (·, y) is convex, which fails
if the directional derivative is flipped. This distinction
is depicted in Figure 1.
Example 2.2. In the case of the differentiable convex
function f2 = k · k22 , Bf2 (x, y) = kx − yk22 follows by
noting f20 (y; y − x) = h2y, y − xi. To analyze the case
of f1 = k · k1 , first consider the univariate case h = | · |.
Either by drawing a picture or checking h0 (·; ·) from
definition, it follows that
(
0
when xy > 0,
Bh (x, y) :=
2|x| otherwise.
Then noting that f10 (·; ·) decomposes
coordinate-wise,
P
it follows that Bf1 (x, y) = i Bh (xi , yi ). Said another
way, Bf1 is twice the l1 distance from x to the farthest
orthant containing y, which bears a resemblance to the
hinge loss.
♦
Bf can also be written in terms of subgradients.
Proposition 2.3. Let a proper convex f and y ∈
ri(dom(f )) be given. Then for any x ∈ dom(f ):

Now suppose there exists y ∈ ri(dom(f )) with
g ∈ ∂f (y); the Fenchel-Young inequality (Rockafellar,
1970, Theorem 23.5) grants Df (x, g) = f (x) − f (y) −
hg, x − yi. Thus, by Proposition 2.3,
Bf (x, y) := max{Df (x, g) : g ∈ ∂f (y)}.

♦

To sanity check Bf , Appendix A states and proves a
number of key Bregman divergence properties, generalized to the case of nondifferentiability. The following
list summarizes these properties; in general, f is closed
proper convex, y ∈ ri(dom(f )), and x ∈ dom(f ).
• Bf (·, y) is convex, proper, nonnegative, and
Bf (y, y) = 0.
• When f is strictly convex, Bf (x, y) = 0 iff x = y.
• Given gx ∈ ri(dom(f ∗ )), supx∈∂f ∗ (gx ) Bf (x, y) =
supgy ∈∂f (y) Bf ∗ (gy , gx ).
• Under some regularity conditions on f , a generalization of the Pythagorean theorem holds, with
Bf replacing squared Euclidean distance.
Over and over, this section depends on relative interiors. What’s so bad about the relative boundary?
The directional derivatives and subgradients break
down. If y ∈ relbd(dom(f )) and x ∈ ri(dom(f )), then
f 0 (y; y − x) = ∞ = Bf (x, y), and there exists no maximizing subgradient as in Proposition 2.3; in fact, one
can not in general guarantee the existence of any subgradients at all.
In just a moment, the cluster model will be developed, where it will be very easy for the second argument argument of Bf to lie on relbd(dom(f )), rendering the divergences infinite and cluster costs meaningless. Worse, it is frequently the case dom(f ) is relatively open, meaning the relative boundary is not in
dom(f )! The smoothing methods of Section 5 work
around these issues. Their approach is simple enough:
they just push relative boundary points inside the relative interior.

• f 0 (y; y − x) and Bf (x, y) are finite, and
• Bf (x, y) := maxg∈∂f (y) f (x) − f (y) − hg, x − yi.
The above characterization will be extremely useful in
proofs, where the existence of a maximizing subgradient ḡy,x will frequently be invoked.

3. Cluster model
Let a finite collection C of points {xi }m
i=1 in some abstract space X — say, documents or vectors — be
given. In order to cluster these with Bregman divergences, the first step is to map them into Rn .

Agglomerative Bregman Clustering

Definition 3.1. A statistic map τ is any function from
X to Rn . Given a finitePset C ⊆ X , overload τ via
averages: τ (C) := |C|−1 x∈C τ (x).
♦
For now, it suffices to think of τ as the identity map
(with X = Rn ), with an added convenience of computing means. Section 4, however, will rely on τ when
constructing exponential families.
Definition 3.2. Given a statistic map τ : X → Rn
and convex function f , the cost of a single cluster C is
X
φf,τ (C) :=
Bf (τ (x), τ (C)).
x∈C

(This cost was the basis for Bregman hard clustering
(Banerjee et al., 2005).)
♦
Example 3.3 (k-means cost). Choose X = Rn ,
τ (x) = x, and f = k · k22 . As discussed in Example
2.2, Bf (x, y) = kx − yk22 , and so φf,τ (C) =
P
2
♦
x∈C kx − τ (C)k2 , precisely the k-means cost.
As such, τ (C) plays the role of a cluster center. While
this may be intuitive for the k-means cost, it requires
justification for general Bregman divergences. The following definition and results bridge this gap.
Definition 3.4. A convex function f is relatively
(Gâteaux) differentiable if, for any y ∈ ri(dom(f )),
there exists g (necessarily any subgradient) so that,
for any x ∈ dom(f ), f 0 (y; y − x) = hg, y − xi.
♦
Every differentiable function is relatively differentiable
(with g = ∇f (y)); fortunately, many relevant convex
functions, in particular those used to construct Bregman divergences between exponential family distributions (cf. Proposition 4.5), will be relatively differentiable.

Continuing, the stage is set to finally construct the
Bregman merge cost.
Definition 3.7. Given two finite subsets C1 , C2 of X ,
the cluster merge cost is simply growth in total cost:
X
∆f,τ (C1 , C2 ) = φf,τ (C1 ∪ C2 ) −
φf,τ (Ci ). ♦
j∈{1,2}

The above expression seems to imply that the computational cost of ∆ scales with the number of points.
But in fact, one need only look at the relevant centers.
Proposition 3.8. Let a proper convex relatively differentiable f and two finite subsets C1 , C2 of X with
τ (Ci ) ∈ ri(dom(f )) be given. Then
X
∆f,τ (C1 , C2 ) =
|Cj |Bf (τ (Cj ), τ (C1 ∪ C2 )).
j∈{1,2}

Example 3.9 (Ward/k-means merge cost). Continuing with the k-means cost from Example 3.3, note that
for j ∈ {1, 2},
kτ (Cj ) − τ (C1 ∪ C2 )k2 =

|C3−j | · kτ (C1 ) − τ (C2 )k2
.
|C1 | + |C2 |

Plugging this into the simplification of ∆f,τ provided
by Proposition 3.8,
X |Cj ||C3−j |2
∆f,τ (C1 , C2 ) =
kτ (C1 ) − τ (C2 )k22
(|C1 | + |C2 |)2
j∈{1,2}

=

|C1 ||C2 |
kτ (C1 ) − τ (C2 )k22 .
|C1 | + |C2 |

This is exactly the Ward merge cost.

♦

4. Exponential families

Under relative differentiability, Bregman divergences
admit a bias-variance style decomposition, which immediately justifies the choice of centroid τ (C).

So far, this manuscript has developed a mathematical basis to clustering with Bregman divergences. But
what does it matter, if examples of meaningful Bregman divergences are few and far between?

Lemma 3.5. Let a proper convex relatively differenn
m
tiable f , points {xi }m
i=1
P⊂ R , and
P weights {αi }i=1 ⊂
R be given, with µ := i αi xi /( j αj ) ∈ ri(dom(f )).
Then, given any point y ∈ ri(dom(f )),
!
m
m
m
X
X
X
αi Bf (xi , y) =
αi Bf (xi , µ) +
αi Bf (µ, y).

The primary mechanism for constructing meaningful
merge costs is to model the clusters as exponential
family distributions. Throughout this section, let ν be
any measure over X , and further stipulate the statistic
map τ is ν-measurable.

i=1

i=1

i=1

Corollary 3.6. Suppose the convex function f is relatively differentiable, let any statistic map τ and any
finite cluster
C ⊆ X be given. Then φf,τ (C) =
P
inf y∈Rn x∈C B(τ (x), y).
Proof. Use µ := τ (C)
Lemma 3.5, and Bf ≥ 0.

=

|C|−1

P

x∈C

τ (x),

Definition 4.1. Given a measurable statistic map τ
and a vector θ ∈ Rn of canonical parameters, the corresponding exponential family distribution has density
pθ (x) := exp(hτ (x), θi − ψ(θ)),
where the normalization term ψ, typically called the
cumulant or log partition function, is simply
Z
ψ(θ) = ln exp(hτ (x), θi)dν(x).
♦

Agglomerative Bregman Clustering

Many standard distributions have this representation.
Example 4.2. Choose X = Rd with ν being Lebesgue
measure, and n = d(d + 1), i.e. Rn = Rd(d+1) . The
map τ (x) = (x, xx> ) will provide for Gaussian densities. In particular, starting from the familiar form,
with mean µ ∈ Rd and positive definite covariance
2
Σ ∈ Rd , the density at x, pθ (x), is
>

K(pθ1 , pθ2 ) = Bψ (θ2 , θ1 ) = Bψ∗ (τ̂1 , τ̂2 ).
Furthermore, if θ1 ∈ ∂ψ ∗ (τ̂2 ), then pθ1 = pθ2 ν-a.e..

−1

exp(−(x − µ) Σ (x − µ)/2)
p
(2π)d |Σ|

= exp τ (x), (Σ−1 µ, −Σ−1 /2)
−

Theorem 4.6. Let any θ1 , θ2 ∈ ri(dom(ψ)) and any
τ̂1 ∈ ∂ψ(θ1 ), τ̂2 ∈ ∂ψ(θ2 ) be given, where ∂ψ ∗ (τ̂2 ) ⊆
ri(dom(ψ)) (for instance, if dom(ψ) is relatively open).
Then

Motivated by Proposition 4.5 and Theorem 4.6, the
choice here is to base the cluster model on Bψ∗ .

1
ln((2π)d |Σ| exp(µ> Σ−1 µ)) .
2


In other words, θ = (Σ−1 µ, −Σ−1 /2). Notice that ψ
(here expanded as 12 ln(. . .)) and θ do not make sense
if Σ is merely positive semi-definite.
♦

Given two clusters {Ci }2i=1 , set τ̂i := τ (Ci ). When
working with these clusters, it is entirely sufficient to
store only these statistics and the cluster sizes, since
τ (C1 ∪ C2 ) = |C1 ∪ C2 |−1 (|C1 |τ̂1 + |C2 |τ̂2 ). Assuming
for interpretability that ψ is differentiable,
since ψ is
R
closed, ψ ∗∗ = ψ, and thus ∇ψ(θ1 ) = τ pθ1 = τ̂1 ; that
is to say, these distributions have their (aptly named)
mean parameterizations as their means. And as provided by Theorem 4.6, even if differentiability fails,
various subgradients of the same mean all effectively
represent the same distributions.

So far so good, but where’s the convex function, and
does the definition of pθ even make sense?
Proposition 4.3. Given a measurable statistic map
τ , the function ψ is well-defined, closed, convex, and
never takes on the value −∞.
Remark 4.4. Notice that Proposition 4.3 did not provide that ψ is proper, only that it is never −∞. Unfortunately, more can not be guaranteed: if ν is Lebesgue
measure over R and τ (x) = 0 for all x, then every
parameter choice θ ∈ R has ψ(θ) = ∞. It is therefore necessary to check, for any provided τ , whether
dom(ψ) is nonempty.
♦

Example 4.7. Suppose X is a finite set, representing
a vocabulary with n words, and ν is counting measure
over X . The statistic map τ converts word k into the
k th basis vector ek . Let τ̂ ∈ Rn++ represent the mean
parameters of a multinomial over this set; observe that

Not only is ψ closed convex, it is about as well-behaved
as any function discussed in this manuscript.
Proposition 4.5. Suppose dom(ψ) is nonempty.
Then ψ is relatively differentiable; in fact, given any
θ ∈ ri(dom(ψ)), any τ̂ ∈ ∂ψ(θ), and any ξ ∈ dom(ψ),
Z
0
ψ (θ; ξ − θ) = hτ̂ , ξ − θi = hτ (x), ξ − θi pθ (x)dν(x).

That is to say, the canonical parameter vector is
θ = ln τ̂ , the coordinate-wise logarithm of the mean
parameters. Proposition
4.5 can be verified directly:
P
(∇ψ(θ))i = eθi / k eθk = τ̂ . Similarly, given another multinomial with mean parameters τ̂ 0 ∈ Rn++
and canonical parameters θ0 = ln τ̂ 0 ,

R

If ψ is fully differentiable at θ,then ∇ψ(θ) = τ pθ .
Since ψ is closed, given τ̂ ∈ ∂ψ(θ), it follows that
θ ∈ ∂ψ ∗ (τ̂ ). There is still cause for concern that other
subgradients at τ̂ lead to different densities, but as will
be shown below, this does not happen.
Now that a relevant convex function ψ has been identified, the question is whether Bψ (or Bψ∗ ) provide a
reasonable notion of distance amongst densities.
This will be answered in two ways. To start, recall the
Kullback-Leibler divergence K between densities p, q:


Z
p(x)
K(p, q) = p(x) ln
dν(x).
q(x)

pθ (ei ) = hτ (i), τ̂ i
Z
= exp(hei , ln τ̂ i) − ln

K(pθ , pθ0 ) =

n
X
i=1

exp(hτ (k), ln τ̂ i)dν(k).


τ̂i ln

τ̂i
τ̂i0


.

The notation Rn++ means strictly positive coordinates:
no word can have zero probability. Without this restriction, it is not possible to map into the canonical parameter space. This is precisely the scenario
the smoothing methods of Section 5 will work around:
the provided clusters are on the relative boundary of
dom(ψ ∗ ), which is either not part of dom(ψ ∗ ) at all, or
as is the case here, causes degenerate Bregman divergences (infinite valued, and lacking subgradients). ♦
Remark 4.8. The multinomials in Example 4.7 have
an overcomplete representation: scaling any canonical parameter vector by a constant gives the same

Agglomerative Bregman Clustering

mean parameter. In general, if two relative interior
canonical parameters θ1 6= θ2 have a common subgradient τ̂ ∈ ∂ψ(θ1 ) ∩ ∂ψ(θ2 ), then it follows that
{θ1 , θ2 } ⊂ ∂ψ ∗ (τ̂ ) (Rockafellar, 1970, Theorem 23.5).
That is to say: this scenario leads to mean parameters
which have distinct subgradients, and are thus points
of nondifferentiability within ri(dom(ψ ∗ )), which necessitate the generalized development of Bregman divergences in this manuscript.
♦
A further example of Gaussians appears in Appendix C.
The second motivation for ∆ψ∗ ,τ is an interpretation
in terms of model fit.
Theorem 4.9. Fix some measurable statistic map
τ , and let two finite subsets C1 , C2 of X be given
with mean parameters {τ (C1 ), τ (C2 )} = {τ̂1 , τ̂2 } ⊆
ri(dom(ψ ∗ )). Choose any canonical parameters θi ∈
∂ψ ∗ (τ̂i ), and for convenience set C3 := C1 ∪ C2 ,
with mean parameter τ̂3 and any canonical parameter
θ3 ∈ ∂ψ ∗ (τ̂3 ). Then
X X
X
∆ψ∗ ,τ (C1 , C2 ) =
ln pθi (x) −
ln pθ3 (x).
i∈{1,2} x∈Ci

x∈C3

5. Smoothing
The final piece of the technical puzzle is the smoothing procedure: most of the above properties — for
instance, that Bf (τ (C1 ), τ (C2 )) < ∞ — depend on
τ (C2 ) ∈ ri(dom(f )). Relative boundary points lead to
degeneracies; for example, this characterizes the Gaussian degeneracy identified in the introduction.
Definition 5.1. Given a (nonempty) convex set S, a
statistic map τ : X → Rn is a smoothing statistic map
for S if, given any finite set C ⊆ X , τ (C) ∈ ri(S). ♦
It turns out to be very easy to construct smoothing
statistic maps.
Theorem 5.2. Let a nonempty convex set S be given.
Let τ0 : X → Rn be a statistic map satisfying, for
any finite C ⊆ X , τ0 (C) ∈ cl(S). Let z ∈ ri(S) and
α ∈ (0, 1) be arbitrary. Given any finite set C ⊆ X ,
define the maps
τ1 (C) := (1 − α)τ0 (C) + αz,
τ2 (C) := τ0 (C) + αz,
In general, τ1 is a smoothing statistic map for S. If additionally S is a convex cone, then τ2 is also a smoothing statistic map for S.
The following two examples smooth Gaussians and
multinomials via Theorem 5.2. The parameters α and

z are chosen from data, and moreover satisfy kαzk ↓ 0
as the total amount of available data grows; that is to
say, τ will more and more closely match τ0 .
Example 5.3 (Smoothing multinomials.). The mean
parameters to a multinomial lie within the probability simplex, a compact convex set. As discussed in
Example 4.7, only the relative interior of the simplex
provides canonical parameters. According to Theorem 5.2, all that remains in fixing this problem is to
determine αz.
The approach here is to interpret the provided multinomial τ0 (C) = τ̂ as based on a finite sample of size
m, and thus the true parameters lie within some confidence interval around τ̂ ; crucially, this confidence
interval intersects the relative interior of the probability simplex. One choice is a Bernstein-based upper
p confidence estimate τ (C) = τ0 (C) + O(1/m +
p(1 − p)/m), where p = 1/n.
♦
Example 5.4 (Smoothing Gaussians.). In the case of
Gaussians, as discussed in Example 4.2, only positive
definite covariance matrices are allowed. But this set
is a convex cone, so Theorem 5.2 reduces the problem
to finding a sensible element to add in.
Consider the case of singleton clusters. Adding a fullrank covariance matrix in to the observed zero covariance matrix is like replacing this singleton with
a constellation of points centered at it. Equivalently,
each point is replaced with a tiny Gaussian, which is
reminiscent of nonparametric density estimation techniques. Therefore one option is to use bandwidth selection techniques; the experiments of Section 7 use the
“normal reference rule” (Bowman & Azzalini, 1997,
Section 2.4.2), trying both the approach of estimating
a bandwidth for each coordinate (suffix -nd), and computing one bandwidth for every direction uniformly,
and simply adding a rescaling of the identity matrix
to the sample covariance (suffix -n).
♦
When there is a probabilistic interpretation of the
clusters, and in particular τ (C) may be viewed as a
maximum likelihood estimate, another approach is to
choose some prior over the parameters, and have τ produce a MAP estimate which also lies in the relative
interior. As stated, this approach will differ slightly
from the one presented here: the weight on the added
element will scale with the cluster size, rather than the
size of the full data, and the relationship of τ (C1 ∪ C2 )
to τ (C1 ) and τ (C2 ) becomes less clear.

6. Clustering algorithm
The algorithm appears in Algorithm 1. Letting T∆f,τ
denote an upper bound on the time to calculate a

Agglomerative Bregman Clustering

Algorithm 1 Agglomerate.
Input Merge cost ∆f,τ , points {xi }m
i=1 ⊆ X .
Output Hierarchical clustering.
Initialize forest as F := {{xi } : i ∈ [m]}.
while |F | > 1 do
Let {Ci , Cj } ⊆ F be any pair minimizing
∆f,τ (Ci , Cj ), as computed by Proposition 3.8.
Remove {Ci , Cj } from F , add in Ci ∪ Cj .
end while
return the single tree within F .

single merge cost, a brute-force implementation (over
m points) takes space O(m) and time O(m3 T∆f,τ ),
whereas caching merge cost computations in a minheap requires space O(m2 ) and time O(m2 (lg(m) +
T∆f,τ )). Please refer Appendix E for more notes on
running times, and a depiction of sample hierarchies
over synthetic data.
If Proposition 3.8 is used to compute ∆f,τ , then only
the sizes and means of clusters need be stored, and
computing this merge cost involves just two Bregman
divergences calculations. As the new mean is a convex
combination of the two old means, computing it takes
time O(n). The Bregman cost itself can be more expensive; for instance, as discussed with Gaussians in
Appendix C, it is necessary to invert a matrix, meaning O(n3 ) steps.

7. Empirical results
Trees generated by Agglomerate are evaluated in
two ways. First, cluster compatibility scores are computed via dendrogram purity and initialization quality
for EM upon mixtures of Gaussians. Secondly, cluster
features are fed into supervised learners.
There are two kinds of data: Euclidean (points in
some Rn ), and text data. There are three Euclidean
data sets: UCI’s glass (214 points in R9 ); 3s and 5s
from the mnist digit recognition problem (1984 training digits and 1984 testing digits in R49 , scaled down
from the original 28x28); UCI’s spambase data (2301
train and 2300 test points in R57 ). Text data is drawn
from the 20 newsgroups data, which has a vocabulary
of 61,188 words; a difficult dichotomy (20n-h), the
pair alt.atheism/talk.religion.misc (856 train
and 569 test documents); an easy dichotomy (20n-e),
the pair rec.sport.hockey/sci.crypt (1192 train
and 794 test documents). Finally, 20n-b collects these
four groups into one corpus.
The various trees are labeled as follows. s-link and
c-link denote single and complete linkage, where l1

Table 1. Dendrogram purity on Euclidean and text data.
glass
spam
mnist35
20n-e
20n-h
20n-b

c-link
0.46
0.59
0.59
c-link
0.60
0.54
0.31

s-link
0.45
0.58
0.51
s-link
0.50
0.52
0.29

km
0.50
0.59
0.69

dg-nd
0.49
0.65
0.62
multi
0.93
0.56
0.62

g-n
0.54
0.60
0.73

distance is used for text, and l2 distance is used for
Euclidean data. km is the Ward/k-means merge cost.
g-n fits full covariance Gaussians, whereas dg-nd fits
diagonal covariance Gaussians; smoothing follows the
data-dependent scheme of Example 5.4. multi fits
multinomials, with the smoothing scheme of Example 5.3.
7.1. Cluster compatibility
Table 1 contains cluster purity scores, a standard dendrogram quality measure, defined as follows. For any
two points with the same label l, find the smallest
cluster C in the tree which contains them both; the
purity with respect to these two points is the fraction
of C having label l. The purity of the dendrogram
is the weighted sum, over all pairs of points sharing
labels, of pairwise purities. The glass, spam, and
20newsgroups data appear in Heller & Ghahramani
(2005); although a direct comparison is difficult, since
those experiments used subsampling and randomized
purity, the Euclidean experiments perform similarly,
and the text experiments fare slightly better here.
For another experiment, now assessing the viability of
Agglomerate as an initialization to EM applied to
mixtures of Gaussians, please see Appendix F.
7.2. Feature generation
The final experiment is to use dendrograms, built from
training data, to generate features for classification
tasks. Given a budget of features k, the top k clusters
{Ci }ki=1 of a specified dendrogram are chosen, and for
any example x, the ith feature is ∆(Ci , {x}). Statistically, this feature measures the amount by which the
model likelihood degrades when Ci is adjusted to accommodate x. The choice of tree was based on training
set purity from Table 1. In all tests, the original features are discarded (i.e., only the k generated features
are used).
Figure 2 shows the performance of logistic regression
classifiers using tree features, as well as SVD features.
The stopping rule used validation set performance.

Agglomerative Bregman Clustering
1.00

1.00

0.95

0.95

0.90

0.90

0.85

0.85

g-n
svd
km

0.80

0.75

0

10

20

30

40

50

(a) mnist35, zoomed in.
1.0

0.75

0

200

400

600

800

(b) mnist35, zoomed out.
0.80

0.9

0.72

0.8

0.64

0.7

0.56

multi
svd
c-link
s-link

0.6

0.5

g-n
svd
km

0.80

0

200

400

600

multi
svd
c-link
s-link

0.48

800

(c) 20n-e.

0.40

0

200

400

600

800

(d) 20n-h.

Figure 2. Comparison of dendrogram features to SVD features; y-axis denotes classification accuracy on test data,
x-axis denotes #features. In the first two plots, mnist35
was used. The SVD can only produce as many features
as the dimension of the data, but the proposed tree continues to improve performance beyond this point. For the
text data tasks 20n-e and 20n-h, tree methods strongly
outperform the SVD. Please see text for details.

Acknowledgements
This work was graciously supported by the NSF under
grant IIS-0713540.

References
Azoury, Katy S. and Warmuth, Manfred K. Relative
loss bounds for on-line density estimation with the
exponential family of distributions. Machine Learning, 43(3):211–246, 2001.
Banerjee, Arindam, Merugu, Srujana, Dhillon, Inderjit S., and Ghosh, Joydeep. Clustering with Bregman divergences. Journal of Machine Learning Research, 6:1705–1749, 2005.
Blundell, C., Teh, Y.W., and Heller, K.A. Bayesian
rose trees. In UAI, 2010.
Borwein, Jonathan and Lewis, Adrian. Convex Analysis and Nonlinear Optimization. Springer Publishing Company, Incorporated, 2000.
Bowman, Adrian W. and Azzalini, Adelchi. Applied

Smoothing Techniques for Data Analysis. Oxford
University Press, USA, 1997.
Brown, Lawrence D. Fundamentals of Statistical Exponential Families. Insitute of Mathematical Statistics, USA, 1986.
Csiszár, Imre and Matúš, František. Generalized
minimizers of convex integral functionals, Bregman distance, Pythagorean identities.
2012.
arXiv:1202.0666v1 [math.OC].
Duda, Richard O., Hart, Peter E., and Stork, David G.
Pattern Classification. Wiley, 2 edition, 2001.
Folland, Gerald B. Real analysis: modern techniques
and their applicatins. Wiley Interscience, 2 edition,
1999.
Fraley, C. Algorithms for model-based gaussian hierarchical clustering. SIAM Journal on Scientific
Computing, 20:270–281, 1998.
Garcia, Vincent, Nielsen, Frank, and Nock, Richard.
Hierarchical gaussian mixture model. In ICASSP,
pp. 4070–4073, 2010.
Gordon, Geoff J. Approximate Solutions to Markov
Decision Processes. PhD thesis, Carnegie Mellon
University, 1999.
Heller, Katherine A. and Ghahramani, Zoubin.
Bayesian hierarchical clustering. In ICML, pp. 297–
304, 2005.
Hiriart-Urruty,
Jean-Baptiste and Lemaréchal,
Claude.
Fundamentals of Convex Analysis.
Springer Publishing Company, Incorporated, 2001.
Iwayama, Makoto and Tokunaga, Takenobu. Hierarchical bayesian clustering for automatic text classification. In IJCAI, pp. 1322–1327, 1995.
Kiwiel, Krzysztof C. Proximal minimization methods
with generalized Bregman functions. SIAM journal
on control and optimization, 35:1142–1168, 1995.
Merugu, Srujana. Distributed Learning using Generative Models. PhD thesis, University of Texas,
Austin, 2006.
Murtagh, Fionn. A Survey of Recent Advances in
Hierarchical Clustering Algorithms. The Computer
Journal, 26(4):354–359, 1983.
Rockafellar, R. Tyrrell. Convex Analysis. Princeton
University Press, 1970.
Slonim, Noam and Tishby, Naftali. Agglomerative information bottleneck. pp. 617–623, 1999.
Wainwright, Martin J and Jordan, Michael I. Graphical Models, Exponential Families, and Variational
Inference. Now Publishers Inc., Hanover, MA, USA,
2008.
Ward, Joe H. Hierarchical grouping to optimize an objective function. Journal of the American Statistical
Association, 58(301):236–244, 1963.

