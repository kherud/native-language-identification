\documentclass[bachelor,german]{info1thesis}

\usepackage[utf8]{inputenc}
%\usepackage[T1]{fontenc}
%\usepackage{fontspec}
%\usepackage{lmodern} TODO: braucht man das?

\usepackage{tabularx}
\usepackage{ltablex}

\usepackage{path}
\usepackage{color}
\usepackage{booktabs}
\usepackage{multirow}

%\usepackage[disable,colorinlistoftodos]{luatodonotes}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Titelseite -- hier Titel und Autorennamen eintragen
\title{Machine Learning for Natural Language Processing} % Geben Sie hier den Titel Ihrer Arbeit an.
\subtitle{am Lehrstuhl für Informatik X}
\author{Konstantin Herud\and Thomas Schaffroth\and Maximilian Meißner} % Geben Sie Ihren Namen an.
%\date{Eingereicht am \abgabedatum}
\titlehead{Julius-Maximilians-Universität Würzburg\\
Institut für Informatik\\
Lehrstuhl für Informatik X\\
Data Science}
\supervisors{Daniel Schlör\and Albin Zehe\and Konstantin Kobs\and Tobias Koopmann} %Prof. Dr. Andreas Hotho\and

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%% Bitte nur ab hier Änderungen vornehmen %%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
    Dieses Dokument soll Studenten an unserem Lehrstuhl bei der Erstellung
    ihrer Abschlussarbeit unterstützen.
    Wir zeigen eine beispielhafte Gliederung einer Arbeit und beschreiben
    die Inhalten der einzelnen Kapitel.
    Zusätzlich geben wir an vielen Stellen auch Hinweise zur Benutzung von
    \LaTeX\ für die Erstellung der Arbeit.
    Im Anhang~\ref{appendix:orga} geben wir ein paar Hinweise zum Ablauf der
    Betreuung von Abschlussarbeiten an unserem Lehrstuhl.

    \paragraph{Zur Handhabung dieses Pakets.}
    In diesem Paket sind Vorlagen für verschiedene Dokumenttypen enthalten, die
    sie als Ausgangspunkt für ihre Arbeit verwenden können.
    Es gibt jeweils Vorlagen für deutsche und englische Arbeiten.
    \begin{itemize}
        \item \verb+template_thesis_de.tex+, \verb+template_thesis_en.tex+:
            Vorlage für Bachelorarbeit bzw. Masterarbeit
        \item \verb+template_seminar_de.tex+, \verb+template_seminar_en.tex+:
            Vorlage für Seminarausarbeitungen und Praktikumsberichte
    \end{itemize}
    Der Quelltext zu diesem Leitfaden ist ebenfalls im Paket enthalten.
    Diesen können Sie als praktisches Beispiel dafür verwenden, wie diese
    Dokumentenklasse angewandt wird.

    \paragraph{Inhalt der Zusammenfassung.}
    Schreiben Sie hier eine Zusammenfassung der Arbeit, vergleichbar mit dem Abstract auf wissenschaftlichen Papers.
    Sie dient dem Leser dazu, einen groben Überblick über die Inhalte zu gewinnen (Problemstellung, verwendeter Lösungsansatz, ggf.\ experimentelle Ergebnisse, gewonnene Erkentnisse).
    Der Umfang soll ca.\ eine halbe Seite betragen.
    Für Seminararbeiten ist diese Zusammenfassung nicht erforderlich.
    
    \emph{Achtung:} Bei Arbeiten auf Englisch fordern die
    Prüfungsordnungen, dass es eine deutsche Zusammenfassung gibt.
    Schreiben Sie in diesem Fall eine englische \emph{und} eine deutsche Zusammenfassung (mit dem gleichen Inhalt).
    Die passenden \LaTeX-Befehle dafür finden Sie in den englischsprachigen
    Vorlagen.

    \paragraph{WARNUNG:} 
    Die vorliegende Version des Leitfadens ist eine \textcolor{red}{Vorabversion}, die noch nicht vollständig ist.
    Sie bezieht sich größtenteils auf die Ausarbeitung von Bachelor- und Masterarbeiten; Seminararbeiten unterscheiden sich davon etwas in Aufbau und Inhalt.

%    \vspace{3em}
%    \textbf{TODOs für die Titelseite:}
%    \todo{Soll der Name des Lehrstuhls für englische Arbeiten übersetzt werden?}
\end{abstract}

\thesistableofcontents






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Methodik}
\textbf{Konstantin Herud} \\

\section{Task 1: Dataset Preparation}

Da verschiedene Informationen das Herkunftsland von Autoren entweder direkt oder indirekt preisgeben, müssen diese aus der Datenbasis entfernt werden. Die Zielsetzung sieht hierbei vor
Namen der Autoren,
E-Mails,
Institutionen und Firmen,
Herkunftsländer,
Förderungen und Danksagungen,
Persönliche Daten
sowie Referenzen
zu entfernen.
Referenzen sind beispielsweise indirekte Hinweise, weil Arbeitsgruppen der gleichen Herkunft und somit dem selben Fachgebiet die selbe Literatur referenzieren. \\
Da diese Aufgabe essentieller Bestandteil der Validität späterer Ergebnisse ist, wurde eine mehrstufige Daten-Pipeline entwickelt, um alle Informationen bestmöglich aus den Texten zu entfernen.

\paragraph{Textextraktion} Im ersten Schritt muss der rohe Text der Dokumente eingelesen werden. Die Daten liegen sowohl in PDF- als auch in Textform vor, wobei letztere durch das Befehlszeilenprogramm \textit{pdftotext} erstellt wurde und somit bereits Potenzial für Fehler bietet. Ursprünglich wurde deshalb ein Ansatz mit dem Werkzeug \textit{pdfminer} verfolgt, um den Text der Dokumente selbstständig zu extrahieren und dabei direkt Strukturinformationen ausnutzen zu können (z.\,B. um Referenz-Blöcke zu erkennen). Bei einigen Dokumenten entstanden jedoch Fehler mit pdfminer, weshalb dieser Ansatz verworfen wurde. So werden in der Pipeline zunächst die Textdateien sowie zugehörige Metadaten eingelesen \footnote{\url{https://github.com/marekrei/ml_nlp_paper_data}}. Da verschiedene spätere Schritt außerdem Informationen über die Zeichenposition des Abstract-Starts brauchen, wird dieser zudem bereits mit einem regulären Ausdruck, unterstützt durch verschiedene Fehlermaßnahmen, bestimmt. So wird beispielsweise überprüft ob der Titel des Dokuments das Wort Abstract enthält. Falls der Start nicht gefunden werden kann oder eine bestimmte Obergrenze überschreitet, wird ein mittelwert-basierter Defaultwert verwendet.
\paragraph{Dokumentkopf} Als Dokumentkopf definieren wir jeglichen Text (in Rohform), der vor dem Abstract erscheint. Die hohe Dichte unterschiedlicher zu entfernender Informationen, gepaart mit Artefakten und Strukturfehlern, machen diese Stufe zu einer der größten Herausforderungen der Aufgabe. So kommen beziehen sich vor allem Namen, E-Mails, Herkunftsländer, Institutionen und persönliche Daten auf diesen Schritt. Initial wurde dafür die Idee verfolgt, \textit{Named-Entity-Recognition} mittels \textit{spaCy} \cite{spacy2} einzusetzen, um all diese Informationen (außer E-Mails, welche leicht durch reguläre Ausdrücke zu erkennen sind) zu entfernen. SpaCy bietet dafür verschiedene vortrainierte Modelle, welche für diese Arbeit mit im Text durch reguläre Ausdrücke erkannten Informationen nachtrainiert wurden. Da dieser Ansatz Entitäten nicht nur zu unverlässlich erkannte (insbesondere keine Phrasen, die über mehrere Tokens reichen), sondern auch zu schlecht klassifzierte wurde ein weiterer Ansatz entwickelt. So wurde ein LSTM-basiertes \cite{Hochreiter1997}, neuronales Netzwerk implementiert, um jede Zeile (im Textdokument, also keine ganzen Sätze) des Vor-Abstract-Texts in die Klassen Autor, E-Mail, Private Informationen, Institution oder Anderes zu unterteilen. Länder werden in einem späteren Schritt entfernt.  Zum Training wurden 250 Dokumente zeilenweise mit einer Kommandozeilenanwendung annotiert. Dabei wurden zufällig Dokumente aus dem Korpus gezogen, allerdings wurde sichergestellt, dass jede Konferenz vorkommt. Zudem sind verschiedene Fehlerfälle enthalten, bei denen der Start des Abstracts nicht korrekt erkannt wurde und somit späterer Text enthalten ist. Das Modell erreicht auf weiteren 50 Dokumenten einen Makro-F1-Wert von etwa 96\%. Die Architektur verfolgt einen ähnlichen Ansatz wie \autoref{eq:embedding}--\ref{eq:zd}, nutzt jedoch nach $X_{zd}$ ein zweites LSTM zur zeilenweisen Klassifikation.
\paragraph{Referenzen}
\paragraph{Gutachter}
\paragraph{Danksagungen}
\paragraph{E-Mails}
\paragraph{Geolokationen}
\paragraph{Fußnoten}
\paragraph{Sprache}

\section{Task 2: Learning to Discriminate}

\begin{itemize}
\itemsep-.5em
\item $z$: Zeilen im Dokument
\item $t$: Tokens pro Zeile (Padding kürzerer Zeilen)
\item $d$: Dimension des Modells (z.\,B. 150)
\item $e$: Embedding-Dimension
\item $c$: Anzahl Klassen
\end{itemize}

\begin{align}
X_{zte} &= \text{Embedding}(X_{zt}) \\ \label{eq:embedding}
X_{ztd} &= \text{LSTM}_t(X_{zte}) \\
A_{zt} &= \text{softmax}_t\left(\sum_d X_{ztd} W_{d}^1\right) \\
X_{zd} &= \sum_t X_{ztd} A_{zt} \\ \label{eq:zd}
A_{z} &= \text{softmax}_z\left(\sum_d X_{zd} W_{d}^2\right) \\
X_{d} &= \sum_z X_{zd} A_z \\
Y_c &= Y_d W_{dc}^3 \label{eq:classification}
\end{align}


\begin{equation}
W_{L,C_i} = \left(\frac{|C_{\max}|}{|C_i|}\right)^\alpha,\;\;\;\alpha = 0.6
\end{equation}

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}

\begin{figure}
     \centering
     \begin{subfigure}[b]{0.8\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/attention-visualized.pdf}
         \subcaption{Bereinigter Text}
         \label{fig:hist-mentions}
     \end{subfigure}
     \begin{subfigure}[b]{0.8\textwidth}
         \centering
         \vspace{.5em}
         \includegraphics[width=\textwidth]{img/attention-visualized-uncensored.pdf}
         \subcaption{Originaltext}
         \label{fig:hist-clusters}
     \end{subfigure}
     \caption{Visualisierung der gelernten Gewichtung einzelner Subtokens zur Klassifikation des Herkunftslandes mit bereinigtem und ursprünglichem Text.}
     \label{fig:droc-histograms}
\end{figure}

%\begin{align}
%A_\text{global} &= A_{zt} \cdot A_{z} \\
%A_\text{global,norm} &= \frac{A_\text{global} - \min A_\text{global}}{\max A_\text{global} - \min A_\text{global}}
%\end{align}

\begin{table}[]
\centering
%\scalebox{1.3}{
\begin{tabular}{@{}clrrrrrrrrrrrr@{}}
\multicolumn{1}{l}{}       & \multicolumn{13}{c}{Voraussage}                                   \\ \cmidrule(l){2-14} 
\multicolumn{1}{l}{}       &     & AU & CA & CN  & FR & DE & IN & IL & JP & SG & CH & UK & USA \\ \cmidrule(l){2-14} 
\multirow{11}{*}{\rotatebox[origin=c]{90}{Wahrheit}} & AU  & 6  &    & 8   &    & 1  &    &    &    &    &    & 7  & 6   \\
                           & CA  & 1  & 8  & 4   &    &    &    &    & 2  &    & 1  & 7  & 32  \\
                           & CN  & 1  & 1  & 188 &    & 1  &    &    & 2  & 1  &    & 1  & 17  \\
                           & FR  &    &    & 1   & 36 & 3  &    &    & 1  &    &    & 2  & 4   \\
                           & DE  &   & 2  & 2   & 2  & 47 &    &    & 1  &    &    & 12 & 11  \\
                           & IN  &    &    & 1   &    &    & 6  &    &    &    &    & 2  & 11  \\
                           & IL  &    & 1  &     & 1  &    &    & 14 & 2  &    &    &    & 10  \\
                           & JP  &    &    & 2   & 1  &    &    &    & 45 &    & 1  & 1  & 6   \\
                           & SG  &    & 1  & 6   &    &    &    &    &    & 9  &    & 2  & 8   \\
                           & CH  &    &    & 3   &    & 7  &    &    &    &    & 4  & 4  & 8   \\
                           & UK  & 3  & 5  & 1   & 6  & 1  & 2  &    & 1  &    & 2  & 66 & 18  \\
                           & USA & 3  & 13 & 38  & 17 & 6  & 1  & 2  & 8  & 2  & 3  & 32 & 746 \\ \cmidrule(l){2-14} 
\end{tabular}
%}
\caption{Konfusionsmatrix der Klassen Australien (AU), Canada (CA), China (CN), Frankreich(FR), Deutschland (DE), Indien (IN), Israel (IL), Japan (JP), Singapur (SG), Schweitz (CH), Großbritannien (UK), Amerika (USA). Leere Zellen implizieren Nullen.}
\end{table}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thesisbibliography
\bibliography{report}



\appendix


\chapter{Formelles/LaTeX}


%\clearpage
%\pdfbookmark[0]{ToDo-Liste}{todos}
%\listoftodos

\end{document}
